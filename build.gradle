import durbin.util.*
import static durbin.weka.WM.*
import durbin.weka.* 

RunBash.enable()

// Add classes used by the build script, basically durbinlib utilities like RunBash
buildscript {
    dependencies {
		//classpath fileTree(dir: '/cluster/bin/durbinlib//target/jar/', include: '*.jar')
		//classpath fileTree(dir: '/Users/james/src/RapidGroovy/', include: '*')
		classpath fileTree(dir:'/Users/james/src/durbinlib/target/jar/', include:'*.jar')
		//classpath files('/Users/james/src/RapidGroovy/')
    }
}

/**********************************************************
*						TASKS
*/

def rootDir = "/hive/users/james/wmm/"
//def rootDir = "/Users/james/ucsc/exp/epigenomics/wmm"


task transposeStateFiles<<{
	new File("./eachstate/").eachFile{statefile->
		if (!statefile.name.contains("_t")){
			println "transpos ./eachstate/${statefile.name} > ./eachstate/${statefile.name}_t"
			"transpos ./eachstate/${statefile.name} > ./eachstate/${statefile.name}_t".bash()			
		}
	}
}


// Perform kmeans clustering on each state and extract a single
// feature out of each cluster to represent each cluster. 
task kMeansSelection(dependsOn: transposeStateFiles)<<{
	"mkdir -p ./kmselection".bash()
		
	def k = 100
	def wm = new WM()
	
	new File("./eachstate/").eachFileMatch(~/.+_t/){dataFile->
		def fileName = "./eachstate/${dataFile.name}"
		def instances = wm.readNumericTab(file:fileName,transpose:true)
		def noIDinstances = wm.removeID(instances)

		def km = SimpleKMeans(I:100,N:k,O:true) // O preserver order
		km.buildClusterer(noIDinstances)

		// Pull out one representative from each cluster
		def representativeSet = []
		def usedClusters = [] as Set
		noIDinstances.eachWithIndex{instance,i->
			def cluster = km.clusterInstance(instance)
			if (!usedClusters.contains(cluster)){
				representativeSet<<instances[i]['ID']
				usedClusters << cluster
			}
		}
		new File("./kmselection/${dataFile.name}.txt").withWriter{w->		
			representativeSet.each{w.writeLine it}
		}
	}
}

// KJD ERROR LOOK INTO: ./rawcluster/ZNF/Rpts
task combineCorrelationFiles<<{
	new File("statekey.tab").splitEachLine("\t"){fields->
		def name = fields[1]
		"combinetables -o ./rawcluster/${name}_all.tab ./rawcluster/${name}_*".bash()
	}

}

task makeCorrelationJobs<<{
	def datadir = "/hive/users/james/wmm/epigenome/eachstate"
	new File(datadir).eachFile{statefile->
		def cmd = "/cluster/bin/wekaMine/wmCorrelateAllPairs"
		def datafile = "$datadir/${statefile.name}"
		def fullcmd = "$cmd -d $datafile -o /hive/users/james/wmm/epigenome/rawcluster/${statefile.name}_ -P -k 500 >> jobs.list"
		println fullcmd
		fullcmd.bash()
	}	
}


// Cluster jobs to compute average of each of 15 HMM states over 
// the ~3000 domains.  Each job takes about 15 minutes to complete. 
task makeMetadataJobs<<{
	def datadir = "/hive/users/james/wmm/epigenome/data/coreMarks/"
	new File(datadir).eachFile{hmmCallBed->
		def fields = hmmCallBed.name.split("_")
		def sampleID = fields[0]
		def cmd = "/hive/users/james/wmm/epigenome/scripts/makeMetadataFileFaster"
		def domains = "/hive/users/james/wmm/epigenome/domains_hesc/combined/total.combined.domain"
		def output = "/hive/users/james/wmm/epigenome/raw_wrangle/${sampleID}.tab"
		println "${cmd} $domains $hmmCallBed $output"
	}
}

// Each makeMetadataFile job creates a file with one column for one sample. 
// This task combines all of these one column files into a feature by samples
// table. 
task combineRawWrangle<<{
	def t = new DynamicTable()
	def wrangleDir = "raw_wrangle/"
	new File(wrangleDir).eachFile{oneSample->
		def colName = oneSample.name
		colName = colName.replaceAll(".tab","")  // chop off .tab suffix. 
		println "Adding $colName"
		oneSample.withReader{r->
			r.splitEachLine("\t"){fields->
				def rowName = fields[0]
				def value = fields[1]
				t[rowName][colName] = value
			}
		}
	}
	println "Writing domainAverage_all.tab ..."
	t.write("domainAverage_all.tab","\t")
}


/* 
Per state files:
./scripts/extractStateFiles.gv domainAverage_all.tab

Correlation jobs were made thus:
/cluster/bin/wekaMine/wmCorrelateAllPairs -d /hive/users/james/wmm/epigenome/domainAverage_all.tab -o /hive/users/james/wmm/epigenome/allpairs_correlation/domains --k 100 > pearsonjobs.txt

*/

